# üöÄ Pipeline ETL Incremental con Airflow -- Arquitectura de Datos en Estilo Productivo

## üìå Descripci√≥n del Proyecto

Este proyecto implementa un **pipeline ETL incremental con enfoque
productivo**, dise√±ado bajo buenas pr√°cticas de ingenier√≠a de datos,
orientado a entornos empresariales.

El pipeline extrae informaci√≥n desde la API de GitHub, la transforma y
la carga en un modelo dimensional optimizado para an√°lisis,
incorporando:

-   Control de incrementalidad mediante watermark por entidad
-   Cargas idempotentes
-   Detecci√≥n autom√°tica de duplicados
-   Validaciones de calidad de datos (Data Quality Checks)
-   Auditor√≠a y trazabilidad por ejecuci√≥n
-   Registro autom√°tico de fallos y causa ra√≠z

El objetivo del proyecto es simular una arquitectura real utilizada en
entornos corporativos donde la confiabilidad, la observabilidad y la
consistencia de los datos son cr√≠ticas.

------------------------------------------------------------------------

# üèó Arquitectura

## üîÑ Flujo General

    GitHub API
         ‚Üì
    RAW (JSON persistente)
         ‚Üì
    STAGING (normalizaci√≥n + deduplicaci√≥n)
         ‚Üì
    DATA WAREHOUSE (modelo dimensional)
         ‚Üì
    Data Quality & Auditor√≠a

------------------------------------------------------------------------
![Arquitectura del Pipeline](architecture_diagram_enterprise.svg)

## üóÇ Capas de Datos

### 1Ô∏è‚É£ Capa RAW

-   Persistencia completa del payload JSON
-   Ingesta inmutable
-   Permite reprocesamiento sin volver a llamar a la API

Tablas: - `raw.github_repos` - `raw.github_commits`

------------------------------------------------------------------------

### 2Ô∏è‚É£ Capa STAGING

-   Normalizaci√≥n de datos
-   Deduplicaci√≥n mediante funci√≥n de ventana (`ROW_NUMBER`)
-   Prevenci√≥n de errores de cardinalidad en UPSERT

Tablas: - `stg.repos` - `stg.commits`

------------------------------------------------------------------------

### 3Ô∏è‚É£ Data Warehouse (Modelo Dimensional)

Modelo optimizado para an√°lisis:

-   `dw.dim_repository`
-   `dw.fact_commits`

Relaci√≥n:

    fact_commits.repo_id ‚Üí dim_repository.repo_id

Este dise√±o permite an√°lisis por repositorio, volumen de commits y
evoluci√≥n temporal.

------------------------------------------------------------------------

# üîÅ Estrategia de Incrementalidad

El pipeline implementa una estrategia robusta de carga incremental
basada en:

-   Tabla de control: `dw.etl_watermark`
-   Watermark por entidad (repositorio)
-   Actualizaci√≥n del watermark √∫nicamente despu√©s de carga exitosa en
    FACT
-   Protecci√≥n contra p√©rdida l√≥gica de datos

------------------------------------------------------------------------

# üß† Decisiones T√©cnicas Clave

### ‚úÖ Cargas Idempotentes

La tabla `stg.commits` utiliza `ON CONFLICT` con clave natural (`sha`),
garantizando:

-   Reprocesamientos seguros
-   Consistencia ante ejecuciones repetidas
-   Eliminaci√≥n de duplicados multi-batch

------------------------------------------------------------------------

### ‚úÖ Deduplicaci√≥n con Ventana Anal√≠tica

Se utiliza:

``` sql
ROW_NUMBER() OVER (PARTITION BY sha ORDER BY raw_ingested_at DESC)
```

Esto evita errores de tipo:

    ON CONFLICT DO UPDATE command cannot affect row a second time

------------------------------------------------------------------------

### ‚úÖ Actualizaci√≥n Correcta del Watermark

El watermark se actualiza √∫nicamente despu√©s de:

    LOAD FACT ‚Üí UPDATE WATERMARK

Nunca en la fase de extracci√≥n.

------------------------------------------------------------------------

# üìä Data Quality Checks Integrados

El pipeline incluye validaciones autom√°ticas que pueden detener la
ejecuci√≥n si se detectan inconsistencias:

-   ‚úî No existen `repo_id` nulos en FACT
-   ‚úî Integridad referencial entre FACT y DIM
-   ‚úî Watermark no adelantado respecto a datos reales
-   ‚úî Validaci√≥n de propagaci√≥n RAW ‚Üí STG

Si alg√∫n check falla:

-   El DAG se marca como FAILED
-   Se registra la causa ra√≠z
-   Se conserva trazabilidad completa

------------------------------------------------------------------------

# üßæ Auditor√≠a y Observabilidad

Tabla: `dw.etl_run_log`

Cada ejecuci√≥n registra:

-   Run ID
-   Fecha de inicio y fin
-   Estado (RUNNING / SUCCESS / FAILED)
-   Task responsable del fallo
-   M√©tricas por capa:
    -   Batches RAW
    -   Registros STG
    -   Registros DIM
    -   Registros FACT

------------------------------------------------------------------------

# üê≥ Ejecuci√≥n Local

## Requisitos

-   Docker
-   Docker Compose

## Levantar entorno

``` bash
docker compose up -d
```

Acceso Airflow:

    http://localhost:8080

------------------------------------------------------------------------

# üõ† Stack Tecnol√≥gico

-   Python
-   Apache Airflow
-   PostgreSQL
-   Docker
-   GitHub REST API
-   SQL avanzado (CTE, ventanas anal√≠ticas, UPSERT)

------------------------------------------------------------------------

# üìà Posibles Mejoras Futuras

-   Particionamiento de tablas FACT
-   Monitoreo de frescura de datos
-   Alertas autom√°ticas (Slack/Email)
-   Integraci√≥n CI/CD
-   Optimizaci√≥n incremental por lote procesado
-   Dashboard de monitoreo en Power BI / Metabase

------------------------------------------------------------------------

# üíº Objetivo Profesional

Este proyecto fue desarrollado como demostraci√≥n pr√°ctica de:

-   Dise√±o de pipelines incrementales robustos
-   Buenas pr√°cticas de ingenier√≠a de datos
-   Gobernanza y confiabilidad de datos
-   Observabilidad en procesos ETL

------------------------------------------------------------------------

# üë®‚Äçüíª Autor

Dubey Angulo\
Ingeniero de Sistemas\
Colombia üá®üá¥
